{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a92b544-28ac-47fd-8189-d88fae22935f",
   "metadata": {},
   "source": [
    "### Name : Muhammad Safi (2303.khi.deg.023)\n",
    "### Assignment Partners: Huzaifa Ali (2303.khi.deg.016)\n",
    "### Shiekh Muhammad Sabih (2303.khi.deg.010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af59038b-9231-4942-beeb-f666867cdce3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sleep\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clear_output, display\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "import pyspark\n",
    "from IPython.display import clear_output, display\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json,udf,when,split\n",
    "from pyspark.sql.streaming import StreamingQuery\n",
    "from pyspark.sql.types import DateType, IntegerType, StringType, StructType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38ab63-78d6-4b6f-8768-de3ace1bda17",
   "metadata": {},
   "source": [
    "## Importing the dataset and naming the columns according to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ec40d-7a41-4b5f-a41a-ec06223e1503",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PySpark Assignment\").getOrCreate()\n",
    "titanic = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"header\", \"false\").csv(\"data/titanic.csv\")\n",
    "columns = [\"PassengerId\",\"Survived\",\"Pclass\",\"Name\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\",\"Cabin\",\"Embarked\",\"Timestamp\"]\n",
    "\n",
    "for i, col_name in enumerate(titanic.columns):\n",
    "    titanic = titanic.withColumnRenamed(col_name, columns[i])\n",
    "titanic.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13107dfb-3781-4e48-8fbd-119ec9e51890",
   "metadata": {},
   "source": [
    "### Modifying the Schema\n",
    "Changing the data type of survived to string and coverting the binary values into string so that we can categorize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb48c52-78be-41d4-bfa9-090674d2f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.withColumn(\"Survived\", when(col(\"Survived\") == 0, \"No\").otherwise(\"Yes\").cast(\"string\"))\n",
    "titanic.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042750d-429f-43f1-8727-3ee9866ced80",
   "metadata": {},
   "source": [
    "### Updated Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51bfa0e-54b8-430c-80a4-dabebda828f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c046106-6bdb-40bc-bac1-c29782afefd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc354f0-9325-4bf5-a222-c3d7ee227ef4",
   "metadata": {},
   "source": [
    "### Checking the minimum, maximum and mean values of the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd83ef86-c431-4268-a5d9-c3223109d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [col_name for col_name, col_type in titanic.dtypes if col_type in ['int', 'bigint', 'float', 'double']]\n",
    "numerical_df = titanic.select(*numerical_cols)\n",
    "\n",
    "\n",
    "min_max_mean=numerical_df.describe()\n",
    "min_max_mean.select(numerical_cols).summary('min','max','mean').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ceecf-7cae-40ff-8e18-be3d5f918456",
   "metadata": {},
   "source": [
    "## Udf function to change the last letter of categorical data to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8406648-3c20-474b-a8b3-43853a2fd486",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\"Sex\",\"Cabin\",\"Embarked\",\"Survived\"]\n",
    "\n",
    "def change_last_letter_after_space(word):\n",
    "    if word is not None:\n",
    "        words = word.split()\n",
    "        for i in range(len(words)):\n",
    "            words[i] = words[i][:-1] + \"1\"\n",
    "        return \" \".join(words)\n",
    "    return word\n",
    "change_last_letter_udf = udf(change_last_letter_after_space, StringType())\n",
    "for column in cat_columns:\n",
    "    titanic = titanic.withColumn(column, change_last_letter_udf(titanic[column]))\n",
    "titanic.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5306e-4995-4f93-8fcf-3e5eae9468a4",
   "metadata": {},
   "source": [
    "## Sorting the DataFrame by its first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e845da4-cc55-484f-9424-27858d7b3c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_titanic = titanic.orderBy(titanic.columns[0])\n",
    "sorted_titanic.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacde722-16fb-429b-a2ec-479e0b65c98e",
   "metadata": {},
   "source": [
    "## Saving the Resultant Dataset in parquet\n",
    "this code overwrites each time the changes are made and the file is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cfa395-eed7-473b-8da8-8d5d121bb828",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sorted_titanic.write.mode('overwrite').parquet(\"titanic_results.parquet\")\n",
    "except:\n",
    "    print('Expection caught')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b11cfd-545f-4980-8f48-a1fef2491f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
